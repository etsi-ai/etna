{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76441d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- SETUP: Generate Dummy Data if missing ---\n",
    "if not os.path.exists(\"dummy_data.csv\"):\n",
    "    print(\"âš ï¸ dummy_data.csv not found. Creating it...\")\n",
    "    data_clf = {\n",
    "        'age': [22, 25, 47, 52, 46, 56, 21, 23, 50, 20],\n",
    "        'salary': [20000, 25000, 50000, 60000, 52000, 80000, 18000, 22000, 65000, 15000],\n",
    "        'bought': [0, 0, 1, 1, 1, 1, 0, 0, 1, 0]\n",
    "    }\n",
    "    pd.DataFrame(data_clf).to_csv(\"dummy_data.csv\", index=False)\n",
    "    print(\"âœ… Created dummy_data.csv\")\n",
    "\n",
    "if not os.path.exists(\"dummy_reg.csv\"):\n",
    "    print(\"âš ï¸ dummy_reg.csv not found. Creating it...\")\n",
    "    data_reg = {\n",
    "        'years_experience': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'level': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],\n",
    "        'salary': [30000, 35000, 50000, 60000, 80000, 85000, 100000, 110000, 130000, 150000]\n",
    "    }\n",
    "    pd.DataFrame(data_reg).to_csv(\"dummy_reg.csv\", index=False)\n",
    "    print(\"âœ… Created dummy_reg.csv\")\n",
    "# ---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963fe96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST 1: CLASSIFICATION ===\n",
      "ğŸ”® Auto-Detected Task: Classification (Target 'bought')\n",
      "âš™ï¸  Preprocessing data...\n",
      "ğŸš€ Initializing Rust Core [In: 2, Out: 2]...\n",
      "ğŸ”¥ Training started...\n",
      "âœ… Training complete!\n",
      "âš™ï¸  Transforming input data...\n",
      "âœ… Predictions: [np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0)]\n",
      "\n",
      "=== TEST 2: REGRESSION ===\n",
      "ğŸ”® User Task: Regression (Target 'salary')\n",
      "âš™ï¸  Preprocessing data...\n",
      "ğŸš€ Initializing Rust Core [In: 2, Out: 1]...\n",
      "ğŸ”¥ Training started...\n",
      "âœ… Training complete!\n",
      "âš™ï¸  Transforming input data...\n",
      "âœ… Predictions: [29324.9, 33226.5, 51102.5, 58576.3, 78740.0, 86213.7, 106377.5, 113851.2, 133283.6, 139879.8]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import etna\n",
    "\n",
    "# 1. Test Classification (Auto-detect should work fine here)\n",
    "print(\"=== TEST 1: CLASSIFICATION ===\")\n",
    "model = etna.Model(\"dummy_data.csv\", target=\"bought\")\n",
    "model.train(epochs=200, lr=0.1)\n",
    "print(f\"âœ… Predictions: {model.predict()}\")\n",
    "\n",
    "# 2. Test Regression (Manually specifying task_type=\"regression\")\n",
    "print(\"\\n=== TEST 2: REGRESSION ===\")\n",
    "# Note: We pass task_type=\"regression\" to skip the auto-detect logic for this tiny dataset\n",
    "model_reg = etna.Model(\"dummy_reg.csv\", target=\"salary\", task_type=\"regression\")\n",
    "model_reg.train(epochs=500, lr=0.001) # More epochs for regression accuracy\n",
    "preds_reg = model_reg.predict()\n",
    "\n",
    "# Formatting for clean output\n",
    "print(f\"âœ… Predictions: {[round(p, 1) for p in preds_reg]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7a3ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST 3: SAVE & TRACK EXPERIMENT ===\n",
      "ğŸ’¾ Saving model artifact and logging metrics to MLflow...\n",
      "Saving model to mvp_regressor.json...\n",
      "Logging to MLflow...\n",
      "ğŸ“ˆ Logging 500 metrics points...\n",
      "Model saved & tracked!\n",
      "View at: http://localhost:5000\n",
      "ğŸƒ View run MVP_Demo_Run at: http://localhost:5000/#/experiments/1/runs/cc5849aa430443d4b7087ab7191cb319\n",
      "ğŸ§ª View experiment at: http://localhost:5000/#/experiments/1\n",
      "âœ… Success! Check the dashboard at http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "# 3. Test Save & Track (New Feature)\n",
    "print(\"\\n=== TEST 3: SAVE & TRACK EXPERIMENT ===\")\n",
    "\n",
    "# We will save the regression model we just trained\n",
    "print(\"ğŸ’¾ Saving model artifact and logging metrics to MLflow...\")\n",
    "\n",
    "# This one function call does everything:\n",
    "# 1. Saves 'mvp_regressor.json' locally\n",
    "# 2. Logs the file to MLflow Artifacts\n",
    "# 3. Logs the loss curve to MLflow Metrics\n",
    "model_reg.save_model(\"mvp_regressor.json\", run_name=\"MVP_Demo_Run\")\n",
    "\n",
    "print(\"âœ… Success! Check the dashboard at http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b61a5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST 4: LOAD MODEL ===\n",
      "ğŸ“‚ Loading 'mvp_regressor.json' back into memory...\n",
      "ğŸ“‚ Loading model from mvp_regressor.json...\n",
      "âœ… Model loaded successfully!\n",
      "âœ… Model loaded successfully!\n",
      "   - Task Type: regression\n",
      "   - Backend: <builtins.EtnaModel object at 0x000001A6FD625C50>\n",
      "ğŸ”® Running prediction with loaded model...\n",
      "âš™ï¸  Transforming input data...\n",
      "âœ… Loaded Predictions: [29324.9, 33226.5, 51102.5, 58576.3, 78740.0, 86213.7, 106377.5, 113851.2, 133283.6, 139879.8]\n"
     ]
    }
   ],
   "source": [
    "# 4. Test Loading (New Feature)\n",
    "print(\"\\n=== TEST 4: LOAD MODEL ===\")\n",
    "\n",
    "# Load the model we just saved in Test 3\n",
    "print(\"ğŸ“‚ Loading 'mvp_regressor.json' back into memory...\")\n",
    "loaded_model = etna.Model.load(\"mvp_regressor.json\")\n",
    "\n",
    "# --- MVP WORKAROUND: Restore Python State ---\n",
    "loaded_model.preprocessor = model_reg.preprocessor\n",
    "loaded_model.task_type = model_reg.task_type\n",
    "loaded_model.target = model_reg.target\n",
    "# --------------------------------------------\n",
    "\n",
    "print(f\"âœ… Model loaded successfully!\")\n",
    "print(f\"   - Task Type: {loaded_model.task_type}\")\n",
    "print(f\"   - Backend: {loaded_model.rust_model}\")\n",
    "\n",
    "# Verify it predicts correctly\n",
    "print(\"ğŸ”® Running prediction with loaded model...\")\n",
    "new_preds = loaded_model.predict(data_path=\"dummy_reg.csv\")\n",
    "\n",
    "# Compare with the previous results (sanity check)\n",
    "print(f\"âœ… Loaded Predictions: {[round(p, 1) for p in new_preds[:10]]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
